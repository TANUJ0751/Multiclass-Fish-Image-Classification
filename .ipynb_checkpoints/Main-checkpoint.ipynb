{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf50004-3496-4aa7-8d27-641cfb0b730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2, InceptionV3, EfficientNetB0\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobile_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2fa9fc-446c-418f-aaa7-c68e4383468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "base_dir = \"./data\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"val\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4b9ac-508e-4588-affa-8b6bb51c084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'val', 'test']\n",
    "distribution = []\n",
    "\n",
    "for split in splits:\n",
    "    split_path = os.path.join(base_dir, split)\n",
    "    for class_name in os.listdir(split_path):\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            num_images = len([\n",
    "                f for f in os.listdir(class_path) \n",
    "                if f.lower().endswith(('.jpg', '.png', '.jpeg'))\n",
    "            ])\n",
    "            distribution.append({\n",
    "                'split': split,\n",
    "                'class': class_name,\n",
    "                'image_count': num_images\n",
    "            })\n",
    "\n",
    "df_dist = pd.DataFrame(distribution)\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(data=df_dist, x='class', y='image_count', hue='split')\n",
    "plt.title(\"Class Distribution Across Train/Val/Test\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67029d-9275-488d-9760-868875cb27d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "def show_sample_images(base_dir, split='train', n=5):\n",
    "    split_path = os.path.join(base_dir, split)\n",
    "    class_dirs = [d for d in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, d))]\n",
    "    \n",
    "    plt.figure(figsize=(15, 3 * len(class_dirs)))\n",
    "    img_index = 1\n",
    "    for class_name in sorted(class_dirs):\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        sample_files = random.sample([\n",
    "            f for f in os.listdir(class_path) \n",
    "            if f.lower().endswith(('.jpg', '.png', '.jpeg'))\n",
    "        ], min(n, len(os.listdir(class_path))))\n",
    "        \n",
    "        for file in sample_files:\n",
    "            img = mpimg.imread(os.path.join(class_path, file))\n",
    "            plt.subplot(len(class_dirs), n, img_index)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(class_name)\n",
    "            img_index += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show 5 images per class from train set\n",
    "show_sample_images(base_dir, split='train', n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e7087-659c-4548-99c4-647546e28a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def get_image_shapes(base_dir, split='train'):\n",
    "    shapes = []\n",
    "    split_path = os.path.join(base_dir, split)\n",
    "    for class_name in os.listdir(split_path):\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        for file in os.listdir(class_path):\n",
    "            if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                try:\n",
    "                    img_path = os.path.join(class_path, file)\n",
    "                    with Image.open(img_path) as img:\n",
    "                        shapes.append(img.size)  # (width, height)\n",
    "                except:\n",
    "                    continue\n",
    "    return shapes\n",
    "\n",
    "# Analyze shapes in train set\n",
    "shapes = get_image_shapes(base_dir, 'train')\n",
    "widths, heights = zip(*shapes)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(widths, bins=20)\n",
    "plt.title(\"Image Width Distribution\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(heights, bins=20)\n",
    "plt.title(\"Image Height Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average Image Size: {np.mean(widths):.1f} x {np.mean(heights):.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc3ad9-3a0f-487e-b7e6-ff56e222205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20,\n",
    "                                   width_shift_range=0.2, height_shift_range=0.2,\n",
    "                                   shear_range=0.2, zoom_range=0.2,\n",
    "                                   horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "test_val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "val_data = test_val_datagen.flow_from_directory(val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')\n",
    "test_data = test_val_datagen.flow_from_directory(test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "\n",
    "class_names = list(train_data.class_indices.keys())\n",
    "num_classes = len(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926bcfdd-0411-48da-b524-c4cd8a5e6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, model_name):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.title(f'{model_name} - Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title(f'{model_name} - Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f\"plots/{model_name}_history.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23796df2-7caa-470b-a128-c59a605e74be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_cnn():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3,3), activation='relu', input_shape=(*IMG_SIZE, 3)),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5753a8-8010-45f5-bbad-9d02ece2fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = build_custom_cnn()\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c647c3f-7d2d-4910-ad54-ff31c0062f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history_cnn = cnn_model.fit(train_data, validation_data=val_data, epochs=20, callbacks=[early_stop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029d0e7-551e-4210-8e5b-ecd00f94ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(\"models/custom_cnn_model.h5\")\n",
    "plot_history(history_cnn, \"Custom_CNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487201ad-040c-49cd-85dd-696b88315530",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = cnn_model.evaluate(test_data, verbose=1)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a6d92c-6093-4fbe-8401-6b2958097d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transfer_model(base_model, preprocess_input_fn, name):\n",
    "    base = base_model(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "    base.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Lambda(preprocess_input_fn, input_shape=(*IMG_SIZE, 3)),\n",
    "        base,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346b9b3-490d-4bbf-bbc8-ca38ddaf32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = {\n",
    "    \"VGG16\": (VGG16, vgg_preprocess),\n",
    "    \"ResNet50\": (ResNet50, resnet_preprocess),\n",
    "    \"MobileNetV2\": (MobileNetV2, mobile_preprocess),\n",
    "    \"InceptionV3\": (InceptionV3, inception_preprocess),\n",
    "    \"EfficientNetB0\": (EfficientNetB0, efficientnet_preprocess)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73357205-b2b2-49fc-abca-59474e4191d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name, (model_func, preprocess) in models_to_train.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    model = build_transfer_model(model_func, preprocess, model_name)\n",
    "    history = model.fit(train_data, validation_data=val_data, epochs=10, callbacks=[early_stop])\n",
    "    model.save(f\"models/{model_name}.h5\")\n",
    "    plot_history(history, model_name)\n",
    "    results[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1782be-3fe8-4e7b-ac82-a8188b3cc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name):\n",
    "    predictions = model.predict(test_data)\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = test_data.classes\n",
    "\n",
    "    print(f\"\\n{model_name} - Classification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
    "    plt.title(f\"{model_name} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(f\"plots/{model_name}_confusion_matrix.png\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ff62d-0619-45ae-92de-fbdccadb577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "evaluate_model(cnn_model, \"Custom_CNN\")\n",
    "for model_name, model in results.items():\n",
    "    evaluate_model(model, model_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "mybase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
